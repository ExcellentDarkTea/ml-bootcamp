{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMalK_oYR-X_"
   },
   "source": [
    "### Task 1: Calling LLM with a Basic Prompt\n",
    "\n",
    "Create the ability to call LLM with a regular text prompt.\n",
    "\n",
    "The prompt should allow obtaining information in simple language on a specific topic. In this task, we want to learn about the topic \"Quantum Computing.\"\n",
    "\n",
    "The model's response should include a definition, key advantages, and current research in this field.\n",
    "\n",
    "Limit the response to 200 characters and specify in the prompt that the answer should be brief (this will save you time and money on generated tokens).\n",
    "\n",
    "You can use either a model from HuggingFace (I recommend Mistral) or ChatGPT4 or ChatGPT3 as the LLM. In both cases, you need to import the necessary \"wrapper\" (i.e., the class that will allow you to initiate the model) from LangChain to call the LLM via API, as well as read your personal token from a file, for example, `creds.json`, which is stored locally and you DO NOT submit it in the homework and DO NOT commit it to git üòè\n",
    "\n",
    "Set your temperature value at your discretion (there is no right or wrong value here) and explain why you chose that specific value for this task.\n",
    "\n",
    "Requests can be made in either Ukrainian or English - consider where and if you want to leave this project later and which language will fit better. In the solutions, prompts should be in Ukrainian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantum computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Explain quantum computing in a way that anyone can understand, even without a technical background.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Olha Shaposhnyk\\anaconda3\\envs\\ml_course\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Quantum computing is a new way to process information using the strange and counterintuitive rules of quantum mechanics. In our everyday life, we use classical computers that work with bits, which are like tiny switches that can be either on or off. Quantum computers, on the other hand, use quantum bits, or qubits, which can exist in multiple states at once.\n",
      "\n",
      "Imagine a coin that can be heads or tails, but also spin at the same time, making it heads and tails at the same time in different directions. This might sound confusing, but it's the key to quantum computing's power. With qubits, quantum computers can process a vast number of possibilities all at once, making them incredibly fast for certain types of calculations.\n",
      "\n",
      "Classical computers are like a single person trying to solve a complex puzzle by looking at one piece at a time. Quantum computers, however, are like a team of people, each looking\n"
     ]
    }
   ],
   "source": [
    "print(mistral.invoke(request))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions 1\n",
    "- For this task, the mistralai library was used, which is free, and it performed well for the current task.\n",
    "- The LLM handled the task well and provided a general definition of how quantum computing differs from classical computing and began to describe the advantages of the methods. The LLM did not provide information on current research, but it seems that it ran out of space due to the 200-token limit.\n",
    "- For the current task, a temperature of 0.2 was chosen, which allows the model to be quite specific and strict during text generation while still being able to be creative. Because with an increase in temperature, the model started to stray from the topic and add a lot of irrelevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UiIzV0UIS0GA"
   },
   "source": [
    "### Task 2: Creating a Parameterized Prompt for Text Generation\n",
    "Now we want to update the previous functionality so that we can pass the topic as a parameter in the prompt. To do this, use `PromptTemplate` from `langchain` and implement a parameterized prompt and a model call with it.\n",
    "\n",
    "Run the updated functionality (prompt + model) for explanations on the topics\n",
    "- \"Bayesian methods in machine learning\"\n",
    "- \"Transformers in machine learning\"\n",
    "- \"Explainable AI\"\n",
    "\n",
    "Display the results of the model's execution on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kcg7EfdNcBDq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\anaconda\\envs\\ml_course\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CURRENT TOPIC IS:  Bayesian methods in machine learning\n",
      "\n",
      "\n",
      "Bayesian methods in machine learning are a way to make predictions or find patterns in data using probabilities. Imagine you have a box with different colored balls, and you want to know what percentage of each color is in the box without looking inside. You can make an educated guess based on the information you have, such as the colors of the balls you've seen before or the total number of balls.\n",
      "\n",
      "In machine learning, we have data instead of balls, and we want to make predictions or find patterns. Bayesian methods allow us to update our beliefs or probabilities about the underlying patterns based on new data.\n",
      "\n",
      "Let's say we have a dataset of emails, and we want to know if an email is spam or not. We can start with some initial beliefs or priors about the probability of an email being spam or not. As we receive more data, we can update our beliefs based on the new information.\n",
      "\n",
      "For example, if we\n",
      "\n",
      "CURRENT TOPIC IS:  Transformers in machine learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\anaconda\\envs\\ml_course\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Transformers are a type of machine learning model that can be thought of as a super-powered version of autocorrelation, a statistical technique used in signal processing to understand the relationship between a signal and a lagged version of itself. In simpler terms, autocorrelation helps us find patterns in data by comparing it to a slightly delayed version of itself.\n",
      "\n",
      "Transformers take this idea and apply it to understanding the relationships between words in a sentence or documents in a collection. Instead of comparing words to a lagged version of themselves, Transformers compare words to all other words in the context, allowing the model to understand the meaning and relationships between words in a more nuanced way.\n",
      "\n",
      "Imagine a large party where everyone is talking at once. Each person's conversation is a sentence, and the overall noise is the collection of all the sentences. Autocorrelation would be like trying to understand one person's conversation by listening to their own words repeated\n",
      "\n",
      "CURRENT TOPIC IS:  Explainable AI\n",
      "\n",
      "\n",
      "Explainable AI (XAI) refers to artificial intelligence (AI) systems that can provide clear and understandable explanations for their decision-making processes. In simpler terms, it's AI that can tell you why it did what it did.\n",
      "\n",
      "Imagine you have a doctor who uses an AI system to help diagnose diseases based on symptoms. With a non-explainable AI, the doctor would just get a diagnosis without any explanation. But with an explainable AI, the doctor would not only get the diagnosis but also receive a detailed explanation of why the AI reached that conclusion based on the patient's symptoms.\n",
      "\n",
      "XAI is important because, as AI systems become more complex, it becomes increasingly difficult for humans to understand why they are making certain decisions. This lack of transparency can lead to mistrust and misunderstanding. Explainable AI helps bridge this gap by providing clear and understandable explanations, making it easier for humans to trust\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\anaconda\\envs\\ml_course\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Explain {topic} in a way that anyone can understand, even without a technical background, but precise enough for a technical audience.\"\n",
    ")\n",
    "\n",
    "topic_list = ['Bayesian methods in machine learning', 'Transformers in machine learning', 'Explainable AI']\n",
    "\n",
    "for topic in topic_list:\n",
    "    print(\"\\nCURRENT TOPIC IS: \", topic)\n",
    "    print(mistral.invoke(prompt.format(topic=topic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Bayesian methods in machine learning are a way to make predictions or find patterns in data using probabilities. Imagine you have a box with different colored balls, and you want to know what percentage of each color is in the box without looking inside. You can make an educated guess based on the information you have, such as the colors of the balls you've seen before or the total number of balls.\n",
      "\n",
      "In machine learning, we have data instead of balls, and we want to make predictions or find patterns. Bayesian methods allow us to update our beliefs or probabilities about the underlying patterns based on new data.\n",
      "\n",
      "Let's say we have a dataset of emails, and we want to know if an email is spam or not. We can start with some initial beliefs or priors about the probability of an email being spam or not. As we receive more data, we can update our beliefs based on the new information.\n",
      "\n",
      "For example, if we\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\anaconda\\envs\\ml_course\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | mistral\n",
    "\n",
    "print(chain.invoke('Bayesian methods in machine learning'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions 2\n",
    "- The same language model was used, but it turned out to be necessary to modify the prompt and add \"but precise enough for a technical audience.\" Because after we placed the prompt in PromptTemplate, it started generating overly simplified and \"childish\" explanations.\n",
    "- A chain was also used, for practice on how it works. We can compare the prompts for the query \"Bayesian methods in machine learning.\" The LLM works quite similarly in both calls, even providing the same example that describes how we can use Bayesian methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9UsL2gXSe-3"
   },
   "source": [
    "### Task 3: Using an Agent to Automate Processes\n",
    "Create an agent that will help automatically search for information about the latest scientific publications in various fields. For example, the agent should find the 5 most recent publications on the topic of artificial intelligence.\n",
    "\n",
    "**Steps:**\n",
    "1. Set up a ReAct type agent in LangChain to perform automatic queries.\n",
    "2. Create a prompt that directs the agent to search for information on the internet or in databases of scientific publications.\n",
    "3. The agent should output a list of publications, each containing the title, authors, and a brief description.\n",
    "\n",
    "To interact with the search, it is necessary to create a `Tool`. In the lecture, we used `serpapi`. You can continue using it or choose another API for searching (some of them are free). A list of various APIs available in LangChain and a pricing guide for queries can be found in a separate document [here](https://hannapylieva.notion.site/API-12994835849480a69b2adf2b8441cbb3?pvs=4).\n",
    "\n",
    "I also leave below an example of using one of the free search APIs - DuckDuckGo (does not require token creation!) - you might like it :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "p56AZ_SnXvTs",
    "outputId": "fcee82cc-03d7-4402-a243-0033596a9ea9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Olha Shaposhnyk\\anaconda3\\envs\\ml_course\\Lib\\site-packages\\langsmith\\client.py:277: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "tools = load_tools([\"ddg-search\"], llm=llm) \n",
    "tools.extend(load_tools([\"arxiv\"], llm=llm))  \n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DuckDuckGoSearchRun(api_wrapper=DuckDuckGoSearchAPIWrapper(region='wt-wt', safesearch='moderate', time='y', max_results=5, backend='auto', source='text')),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000))]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo find recent publications on the topic of 'Artificial Intelligence', I will search for relevant papers on arXiv, as it is a comprehensive source for scientific articles in this field.\n",
      "\n",
      "Action: arxiv\n",
      "Action Input: Artificial Intelligence\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2023-04-06\n",
      "Title: The Governance of Physical Artificial Intelligence\n",
      "Authors: Yingbo Li, Anamaria-Beatrice Spulber, Yucong Duan\n",
      "Summary: Physical artificial intelligence can prove to be one of the most important\n",
      "challenges of the artificial intelligence. The governance of physical\n",
      "artificial intelligence would define its responsible intelligent application in\n",
      "the society.\n",
      "\n",
      "Published: 2020-05-21\n",
      "Title: Does an artificial intelligence perform market manipulation with its own discretion? -- A genetic algorithm learns in an artificial market simulation\n",
      "Authors: Takanobu Mizuta\n",
      "Summary: Who should be charged with responsibility for an artificial intelligence\n",
      "performing market manipulation have been discussed. In this study, I\n",
      "constructed an artificial intelligence using a genetic algorithm that learns in\n",
      "an artificial market simulation, and investigated whether the artificial\n",
      "intelligence discovers market manipulation through learning with an artificial\n",
      "market simulation despite a builder of artificial intelligence has no intention\n",
      "of market manipulation. As a result, the artificial intelligence discovered\n",
      "market manipulation as an optimal investment strategy. This result suggests\n",
      "necessity of regulation, such as obligating builders of artificial intelligence\n",
      "to prevent artificial intelligence from performing market manipulation.\n",
      "\n",
      "Published: 2015-07-01\n",
      "Title: Impact of Artificial Intelligence on Economic Theory\n",
      "Authors: Tshilidzi Marwala\n",
      "Summary: Artificial intelligence has impacted many aspects of human life. This paper\n",
      "studies the impact of artificial intelligence on economic theory. In particular\n",
      "we study the impact of artificial intelligence on the theory of bounded\n",
      "rationality, efficient market hypothesis and prospect theory.\u001b[0m\u001b[32;1m\u001b[1;3mI have found three relevant publications on the topic of 'Artificial Intelligence' from arXiv. To provide a more comprehensive list, I will search for additional recent publications using DuckDuckGo.\n",
      "\n",
      "Action: duckduckgo_search\n",
      "Action Input: recent publications on Artificial Intelligence 2023\u001b[0m\u001b[36;1m\u001b[1;3mFind the latest research papers and news in Artificial Intelligence. Read stories and opinions from top researchers in our research community. ... Artificial Intelligence. Uncover the latest and most impactful research in Artificial Intelligence. Explore pioneering discoveries, insightful ideas and new methods from leading researchers in the ... In the new report, foundation models dominate, benchmarks fall, prices skyrocket, and on the global stage, the U.S. overshadows. \"Data Page: Annual scholarly publications on artificial intelligence\", part of the following publication: Charlie Giattino, Edouard Mathieu, Veronika Samborska and Max Roser (2023) - \"Artificial Intelligence\". Data adapted from Center for Security and Emerging Technology. Between 2013 and 2023, the scientific literature on artificial intelligence grew at an exponential rate. The subject appears to be gaining even greater popularity across a wide range of fields. Although interest in the area is now at its peak, there is a scarcity of comprehensive bibliometric study. As a result, a new perspective on the constantly changing accomplishments, contributions, and ... The most recent edition of the \"UN Activities on AI Report\" represents a collaborative endeavor between the International Telecommunication Union (ITU) and 46 United Nations agencies and bodies. This comprehensive report showcases 408 artificial intelligence (AI) cases and projects run by the UN system, encompassing all 17 Sustainable Development Goals (SDGs). The initiatives range from ...\u001b[0m\u001b[32;1m\u001b[1;3mI have found three relevant publications on the topic of 'Artificial Intelligence' from arXiv. To complete the list, I will summarize the findings and provide a list of five publications, including the title, authors, and a brief summary of each paper.\n",
      "\n",
      "1. **Title:** The Governance of Physical Artificial Intelligence  \n",
      "   **Authors:** Yingbo Li, Anamaria-Beatrice Spulber, Yucong Duan  \n",
      "   **Summary:** This paper discusses the governance of physical artificial intelligence, emphasizing its importance as a challenge in AI. It explores how governance can ensure responsible and intelligent application in society.  \n",
      "   [Link to paper](https://arxiv.org/abs/2304.006)\n",
      "\n",
      "2. **Title:** Does an artificial intelligence perform market manipulation with its own discretion? -- A genetic algorithm learns in an artificial market simulation  \n",
      "   **Authors:** Takanobu Mizuta  \n",
      "   **Summary:** The study investigates whether AI can discover market manipulation strategies through learning in an artificial market simulation. It highlights the need for regulation to prevent AI from engaging in market manipulation.  \n",
      "   [Link to paper](https://arxiv.org/abs/2005.021)\n",
      "\n",
      "3. **Title:** Impact of Artificial Intelligence on Economic Theory  \n",
      "   **Authors:** Tshilidzi Marwala  \n",
      "   **Summary:** This paper examines the impact of AI on economic theory, focusing on bounded rationality, efficient market hypothesis, and prospect theory. It discusses how AI influences these economic concepts.  \n",
      "   [Link to paper](https://arxiv.org/abs/1507.001)\n",
      "\n",
      "4. **Title:** UN Activities on AI Report  \n",
      "   **Authors:** International Telecommunication Union (ITU) and 46 United Nations agencies  \n",
      "   **Summary:** This report showcases 408 AI cases and projects run by the UN system, covering all 17 Sustainable Development Goals (SDGs). It highlights the collaborative efforts of the UN in utilizing AI for global development.  \n",
      "   [Link to report](https://www.itu.int/en/ITU-T/AI/Pages/default.aspx)\n",
      "\n",
      "5. **Title:** Data Page: Annual scholarly publications on artificial intelligence  \n",
      "   **Authors:** Charlie Giattino, Edouard Mathieu, Veronika Samborska, Max Roser  \n",
      "   **Summary:** This publication provides a bibliometric study of the exponential growth in AI literature from 2013 to 2023. It offers insights into the increasing popularity and contributions of AI research across various fields.  \n",
      "   [Link to publication](https://ourworldindata.org/artificial-intelligence)\n",
      "\n",
      "These publications provide a diverse overview of recent research and developments in the field of Artificial Intelligence.\u001b[0mInvalid Format: Missing 'Action:' after 'Thought:'\u001b[32;1m\u001b[1;3mI have compiled a list of five publications on the topic of 'Artificial Intelligence', including titles, authors, and brief summaries.\n",
      "\n",
      "Final Answer:\n",
      "\n",
      "1. **Title:** The Governance of Physical Artificial Intelligence  \n",
      "   **Authors:** Yingbo Li, Anamaria-Beatrice Spulber, Yucong Duan  \n",
      "   **Summary:** This paper discusses the governance of physical artificial intelligence, emphasizing its importance as a challenge in AI. It explores how governance can ensure responsible and intelligent application in society.  \n",
      "   [Link to paper](https://arxiv.org/abs/2304.006)\n",
      "\n",
      "2. **Title:** Does an artificial intelligence perform market manipulation with its own discretion? -- A genetic algorithm learns in an artificial market simulation  \n",
      "   **Authors:** Takanobu Mizuta  \n",
      "   **Summary:** The study investigates whether AI can discover market manipulation strategies through learning in an artificial market simulation. It highlights the need for regulation to prevent AI from engaging in market manipulation.  \n",
      "   [Link to paper](https://arxiv.org/abs/2005.021)\n",
      "\n",
      "3. **Title:** Impact of Artificial Intelligence on Economic Theory  \n",
      "   **Authors:** Tshilidzi Marwala  \n",
      "   **Summary:** This paper examines the impact of AI on economic theory, focusing on bounded rationality, efficient market hypothesis, and prospect theory. It discusses how AI influences these economic concepts.  \n",
      "   [Link to paper](https://arxiv.org/abs/1507.001)\n",
      "\n",
      "4. **Title:** UN Activities on AI Report  \n",
      "   **Authors:** International Telecommunication Union (ITU) and 46 United Nations agencies  \n",
      "   **Summary:** This report showcases 408 AI cases and projects run by the UN system, covering all 17 Sustainable Development Goals (SDGs). It highlights the collaborative efforts of the UN in utilizing AI for global development.  \n",
      "   [Link to report](https://www.itu.int/en/ITU-T/AI/Pages/default.aspx)\n",
      "\n",
      "5. **Title:** Data Page: Annual scholarly publications on artificial intelligence  \n",
      "   **Authors:** Charlie Giattino, Edouard Mathieu, Veronika Samborska, Max Roser  \n",
      "   **Summary:** This publication provides a bibliometric study of the exponential growth in AI literature from 2013 to 2023. It offers insights into the increasing popularity and contributions of AI research across various fields.  \n",
      "   [Link to publication](https://ourworldindata.org/artificial-intelligence)\n",
      "\n",
      "These publications provide a diverse overview of recent research and developments in the field of Artificial Intelligence.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"Search for publications, papers, or news on the topic of 'Artificial Intelligence'. Provide 5 publications on this topic. Provide a list of publications, including the title, authors, and a brief summary of each paper (link if possible).\",\n",
       " 'output': '1. **Title:** The Governance of Physical Artificial Intelligence  \\n   **Authors:** Yingbo Li, Anamaria-Beatrice Spulber, Yucong Duan  \\n   **Summary:** This paper discusses the governance of physical artificial intelligence, emphasizing its importance as a challenge in AI. It explores how governance can ensure responsible and intelligent application in society.  \\n   [Link to paper](https://arxiv.org/abs/2304.006)\\n\\n2. **Title:** Does an artificial intelligence perform market manipulation with its own discretion? -- A genetic algorithm learns in an artificial market simulation  \\n   **Authors:** Takanobu Mizuta  \\n   **Summary:** The study investigates whether AI can discover market manipulation strategies through learning in an artificial market simulation. It highlights the need for regulation to prevent AI from engaging in market manipulation.  \\n   [Link to paper](https://arxiv.org/abs/2005.021)\\n\\n3. **Title:** Impact of Artificial Intelligence on Economic Theory  \\n   **Authors:** Tshilidzi Marwala  \\n   **Summary:** This paper examines the impact of AI on economic theory, focusing on bounded rationality, efficient market hypothesis, and prospect theory. It discusses how AI influences these economic concepts.  \\n   [Link to paper](https://arxiv.org/abs/1507.001)\\n\\n4. **Title:** UN Activities on AI Report  \\n   **Authors:** International Telecommunication Union (ITU) and 46 United Nations agencies  \\n   **Summary:** This report showcases 408 AI cases and projects run by the UN system, covering all 17 Sustainable Development Goals (SDGs). It highlights the collaborative efforts of the UN in utilizing AI for global development.  \\n   [Link to report](https://www.itu.int/en/ITU-T/AI/Pages/default.aspx)\\n\\n5. **Title:** Data Page: Annual scholarly publications on artificial intelligence  \\n   **Authors:** Charlie Giattino, Edouard Mathieu, Veronika Samborska, Max Roser  \\n   **Summary:** This publication provides a bibliometric study of the exponential growth in AI literature from 2013 to 2023. It offers insights into the increasing popularity and contributions of AI research across various fields.  \\n   [Link to publication](https://ourworldindata.org/artificial-intelligence)\\n\\nThese publications provide a diverse overview of recent research and developments in the field of Artificial Intelligence.'}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke({\n",
    "    'input': \"Search for publications, papers, or news on the topic of 'Artificial Intelligence'. Provide 5 publications on this topic. Provide a list of publications, including the title, authors, and a brief summary of each paper (link if possible).\"\n",
    "})\n",
    "\n",
    "save_response = response\n",
    "save_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Title:** The Governance of Physical Artificial Intelligence  \n",
      "   **Authors:** Yingbo Li, Anamaria-Beatrice Spulber, Yucong Duan  \n",
      "   **Summary:** This paper discusses the governance of physical artificial intelligence, emphasizing its importance as a challenge in AI. It explores how governance can ensure responsible and intelligent application in society.  \n",
      "   [Link to paper](https://arxiv.org/abs/2304.006)\n",
      "\n",
      "2. **Title:** Does an artificial intelligence perform market manipulation with its own discretion? -- A genetic algorithm learns in an artificial market simulation  \n",
      "   **Authors:** Takanobu Mizuta  \n",
      "   **Summary:** The study investigates whether AI can discover market manipulation strategies through learning in an artificial market simulation. It highlights the need for regulation to prevent AI from engaging in market manipulation.  \n",
      "   [Link to paper](https://arxiv.org/abs/2005.021)\n",
      "\n",
      "3. **Title:** Impact of Artificial Intelligence on Economic Theory  \n",
      "   **Authors:** Tshilidzi Marwala  \n",
      "   **Summary:** This paper examines the impact of AI on economic theory, focusing on bounded rationality, efficient market hypothesis, and prospect theory. It discusses how AI influences these economic concepts.  \n",
      "   [Link to paper](https://arxiv.org/abs/1507.001)\n",
      "\n",
      "4. **Title:** UN Activities on AI Report  \n",
      "   **Authors:** International Telecommunication Union (ITU) and 46 United Nations agencies  \n",
      "   **Summary:** This report showcases 408 AI cases and projects run by the UN system, covering all 17 Sustainable Development Goals (SDGs). It highlights the collaborative efforts of the UN in utilizing AI for global development.  \n",
      "   [Link to report](https://www.itu.int/en/ITU-T/AI/Pages/default.aspx)\n",
      "\n",
      "5. **Title:** Data Page: Annual scholarly publications on artificial intelligence  \n",
      "   **Authors:** Charlie Giattino, Edouard Mathieu, Veronika Samborska, Max Roser  \n",
      "   **Summary:** This publication provides a bibliometric study of the exponential growth in AI literature from 2013 to 2023. It offers insights into the increasing popularity and contributions of AI research across various fields.  \n",
      "   [Link to publication](https://ourworldindata.org/artificial-intelligence)\n",
      "\n",
      "These publications provide a diverse overview of recent research and developments in the field of Artificial Intelligence.\n"
     ]
    }
   ],
   "source": [
    "print(save_response['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions 3\n",
    "\n",
    "- For the current agent, we connected various tools:\n",
    "    - ddg-search for searching the internet for various articles on the topic\n",
    "    - arxiv - a wrapper specifically designed for searching scientific articles in the open database arXiv\n",
    "- In the initial iterations, free versions of LLMs like Mistral and gemma were used, but they were prone to strong hallucinations, generating unrealistic article titles, inventing authors, and it was very difficult to \"force\" them to execute requests correctly.\n",
    "- For the final solution, gpt-4o was connected with a temperature of 0 (because we only need real articles, nothing additional should be invented). It finds articles excellently both in arXiv and on the internet in general; all the information provided by the queries is real and corresponds to reality.\n",
    "- HOWEVER, there is a problem with arXiv that the link is not fully functional. The last digits after `.` do not correspond to reality (there are 3 instead of 5 as it should be). This may be a problem with the arXiv wrapper, as there is no such issue with generating working links from the internet.\n",
    "- **Does an artificial intelligence perform market manipulation with its own discretion? -- A genetic algorithm learns in an artificial market simulation** \n",
    "    - Real link https://arxiv.org/abs/2005.10488\n",
    "    - Generated   https://arxiv.org/abs/2005.021\n",
    "\n",
    "- **The Governance of Physical Artificial Intelligence**  \n",
    "    - Real link https://arxiv.org/abs/2304.02924 \n",
    "    - Generated    https://arxiv.org/abs/2304.006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOqujC6qY_NY"
   },
   "source": [
    "### Task 4: Creating an Assistant Agent for Solving Business Problems\n",
    "\n",
    "Create an agent that helps solve business analytics tasks. The agent should assist the user in creating a sales forecast for the next year, taking into account the level of inflation and weather conditions. The agent should be able to use Python and browse the internet to obtain current data.\n",
    "\n",
    "**Steps:**\n",
    "1. Set up the agent that will work with analytical data provided in text. The user writes\n",
    "\n",
    "```\n",
    "We export oranges from Brazil. In 2021 we exported 200 tons, in 2022 - 190 tons, in 2023 - 210 tons, and in 2024 which has not yet ended - 220 tons. Make an estimate of how many oranges we will be able to export in 2025 considering the weather conditions in Brazil and the global demand for oranges based on the economic situation.\n",
    "```\n",
    "\n",
    "2. Create a request to the agent that contains a clear task ‚Äì to provide the result of the business analysis or to state that it cannot do so along with the user's request (it can simply be all in one message).\n",
    "\n",
    "3. Run the agent and analyze the results. What can be improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UK6KA9PyRS0L"
   },
   "outputs": [],
   "source": [
    "python_repl = PythonREPL()\n",
    "python_tool = Tool(\n",
    "    name=\"python_repl\",\n",
    "    description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you necessarily should print it out with `print(...)`. Otherwise you won't see the result! It's very important.\",\n",
    "    func=python_repl.run,\n",
    ")\n",
    "python_tool.name = \"python_interpreter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('creds.json') as file:\n",
    "  creds = json.load(file)\n",
    "os.environ[\"OPENAI_API_KEY\"] = creds[\"OPENAI_API_KEY\"]\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Olha Shaposhnyk\\anaconda3\\envs\\ml_course\\Lib\\site-packages\\langsmith\\client.py:277: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"SERPAPI_API_KEY\"] = creds[\"SERPAPI_API_KEY\"]\n",
    "tools = load_tools([\"serpapi\"], llm=llm)\n",
    "tools.append(python_tool)\n",
    "prompt = hub.pull(\"hwchase17/react\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'} template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}'\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo estimate the export of oranges from Brazil in 2025, I would need to consider several factors, including historical export data, weather conditions in Brazil, and global demand for oranges based on the economic situation. I have historical data for the years 2021 to 2024, but I need to gather information on the current weather conditions in Brazil and the global demand for oranges.\n",
      "\n",
      "Action: Search\n",
      "Action Input: \"Brazil weather conditions 2024 impact on orange production\"\u001b[0m\u001b[36;1m\u001b[1;3mDespite this decrease, Brazil's production is anticipated to recover slightly from the current season, which was the lowest since 1988. Post forecasts orange weight at 160 grams/5.64 ounces in MY 2024/25, three percent lighter than Post's previous estimate of 165 grams for MY 2023/24 due to adverse weather conditions.\u001b[0m\u001b[32;1m\u001b[1;3mThe weather conditions in Brazil have been challenging, leading to a decrease in orange production. However, there is an expectation of a slight recovery in production. This suggests that while weather conditions have been adverse, they may not significantly hinder production in 2025.\n",
      "\n",
      "Next, I need to gather information on the global demand for oranges based on the current economic situation.\n",
      "\n",
      "Action: Search\n",
      "Action Input: \"global demand for oranges 2024 economic situation\"\u001b[0m\u001b[36;1m\u001b[1;3mOranges Market size will be USD 3915.2 million in 2024 and will expand at a compound annual growth rate (CAGR) of 4.80% from 2024 to 2031. The base year for the calculation is 2024. The historical will be 2021 to 2024. The year 2025 will be estimated one while the forecasted data will be from year 2025 to 2033.\u001b[0m\u001b[32;1m\u001b[1;3mThe global demand for oranges is expected to grow at a compound annual growth rate (CAGR) of 4.80% from 2024 to 2031. This indicates a positive trend in demand, which could support an increase in exports if production conditions allow.\n",
      "\n",
      "Given the historical export data, the challenging but slightly recovering weather conditions in Brazil, and the growing global demand for oranges, I can make an estimate for 2025.\n",
      "\n",
      "To estimate the export for 2025, I will consider the average growth in exports from 2021 to 2024 and adjust it based on the expected recovery in production and the positive demand trend.\n",
      "\n",
      "Action: python_interpreter\n",
      "Action Input: \"\"\"\n",
      "# Historical export data\n",
      "exports = [200, 190, 210, 220]\n",
      "\n",
      "# Calculate the average annual growth rate from 2021 to 2024\n",
      "growth_rates = [(exports[i] - exports[i-1]) / exports[i-1] for i in range(1, len(exports))]\n",
      "average_growth_rate = sum(growth_rates) / len(growth_rates)\n",
      "\n",
      "# Adjust the growth rate for 2025 considering the slight recovery in production and positive demand trend\n",
      "adjusted_growth_rate = average_growth_rate + 0.02  # Adding 2% for recovery and demand\n",
      "\n",
      "# Estimate exports for 2025\n",
      "estimated_exports_2025 = exports[-1] * (1 + adjusted_growth_rate)\n",
      "print(estimated_exports_2025)\n",
      "\"\"\"\u001b[0m\u001b[33;1m\u001b[1;3m231.94469507101084\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3mThe estimated export of oranges from Brazil in 2025, considering the historical data, slight recovery in production due to weather conditions, and the positive trend in global demand, is approximately 232 tonnes.\n",
      "\n",
      "Final Answer: The estimated export of oranges from Brazil in 2025 is approximately 232 tonnes.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'We export oranges from Brazil. In 2021, we exported 200 tonnes, in 2022 - 190 tonnes, in 2023 - 210 tonnes, in 2024, which has not yet ended - 220 tonnes. Make an estimate of how much we can export oranges in 2025, given the weather conditions in Brazil and the demand for oranges in the world based on the economic situation. If you cannot perform this analysis, explicitly state that you cannot do so.', 'output': 'The estimated export of oranges from Brazil in 2025 is approximately 232 tonnes.'}\n"
     ]
    }
   ],
   "source": [
    "question = (\n",
    "    \"We export oranges from Brazil. In 2021, we exported 200 tonnes, in 2022 - 190 tonnes, \"\n",
    "    \"in 2023 - 210 tonnes, in 2024, which has not yet ended - 220 tonnes. \"\n",
    "    \"Make an estimate of how much we can export oranges in 2025, given the weather conditions in Brazil \"\n",
    "    \"and the demand for oranges in the world based on the economic situation. \"\n",
    "    \"If you cannot perform this analysis, explicitly state that you cannot do so.\"\n",
    ")\n",
    "\n",
    "response = agent_executor.invoke({\"input\": question})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions 4\n",
    "\n",
    "- For this task, two settings were used for the agent to be able to search the internet for information (serpapi) and to be able to write code in Python (PythonREPL).\n",
    "- Similar to the previous task, only gpt-4o was able to handle the task.\n",
    "- Our forecast *The estimated export of oranges from Brazil in 2025 is approximately 232 tonnes*, which seems quite logical based on its reasoning. We have weather conditions and tried to take into account economic indicators. Thus, in addition to the direct estimation of the coefficient of how much demand has increased on average, the model also added +2% to the demand based on the information it found on the internet. However, where exactly the 2% came from is not entirely clear; it seems the model made some additional assumptions.\n",
    "- Overall, its result looks plausible.\n",
    "- Model improvements:\n",
    "\n",
    "    - To improve the model, first and foremost, more data and details are needed. It was difficult for me to understand how to account for weather conditions on average over a year (too wide a range between the minimum and maximum); it would be better to have at least export data for each month, and from the month, we would be better able to average the weather conditions and determine how critical they are.\n",
    "    - It is also possible to clarify which specific economic situations should be focused on, as there are quite a few, and the LLM may accidentally focus on less prioritized indicators during the search. To avoid having to clarify independently, the prompt can be improved and ask the agent to first highlight 2-3 key economic indicators that are most important for the export of oranges, and only after that ask it to consider them in the forecast."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUPArbcFJKzJ"
   },
   "source": [
    "# Unbalanced classification\n",
    "\n",
    "In this homework, we will practice solving a multi-class classification problem using logistic regression with One-vs-Rest and One-vs-One strategies, evaluate the quality of the models, and compare the strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f4tzX6YomVv"
   },
   "source": [
    "### Task and Data Description\n",
    "\n",
    "**Context**\n",
    "\n",
    "In this homework, we are working with data on customer segmentation.\n",
    "\n",
    "Customer segmentation is the practice of dividing a customer base into groups of individuals who are similar to each other based on certain criteria that are relevant for marketing, such as age, gender, interests, and spending habits.\n",
    "\n",
    "Companies that use customer segmentation operate under the assumption that each customer is unique and that their marketing efforts will be more effective if they target specific, smaller groups with messages that these consumers will find relevant and that will encourage them to make a purchase. Companies also hope to gain a deeper understanding of their customers' preferences and needs in order to identify what each segment values most, allowing them to tailor marketing materials more accurately to that segment.\n",
    "\n",
    "**Content**.\n",
    "\n",
    "An automotive company plans to enter new markets with its existing products (P1, P2, P3, P4, and P5). After extensive marketing research, they concluded that the behavior of the new market is similar to their existing market.\n",
    "\n",
    "In their existing market, the sales team classified all customers into 4 segments (A, B, C, D). They then conducted segmented outreach and communication with different customer segments. This strategy worked extremely well for them. They plan to use the same strategy in new markets and have identified 2627 new potential customers.\n",
    "\n",
    "You need to help the manager predict the correct group for the new customers.\n",
    "\n",
    "In this homework, we will use the data `customer_segmentation_train.csv` [download data](https://drive.google.com/file/d/1VU1y2EwaHkVfr5RZ1U4MPWjeflAusK3w/view?usp=sharing). This is `train.csv` from this [competition](https://www.kaggle.com/datasets/abisheksudarshan/customer-segmentation/data?select=train.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZFXPKx1JX-3"
   },
   "source": [
    "**Task 1.** Download and prepare the dataset for analysis. Handle missing values and perform necessary encoding of categorical features. Split into training and testing sets, where the test set is 20%. Remember that it is better to perform all preprocessing on the training set and only use already trained transformers on the test set. However, in this case, since there are not many values in the categories, you can process the original data and then split it - this is simpler. You can also implement processing and model training with pipelines. Choose what is more convenient for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-mwGqPS5GAT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "path = \"../../../data/\"\n",
    "df = pd.read_csv(path + 'customer_segmentation_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Gender Ever_Married  Age Graduated     Profession  Work_Experience  \\\n",
       "0  462809    Male           No   22        No     Healthcare              1.0   \n",
       "1  462643  Female          Yes   38       Yes       Engineer              NaN   \n",
       "2  466315  Female          Yes   67       Yes       Engineer              1.0   \n",
       "3  461735    Male          Yes   67       Yes         Lawyer              0.0   \n",
       "4  462669  Female          Yes   40       Yes  Entertainment              NaN   \n",
       "\n",
       "  Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "0            Low          4.0  Cat_4            D  \n",
       "1        Average          3.0  Cat_4            A  \n",
       "2            Low          1.0  Cat_6            B  \n",
       "3           High          2.0  Cat_6            B  \n",
       "4           High          6.0  Cat_6            A  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8068 entries, 0 to 8067\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ID               8068 non-null   int64  \n",
      " 1   Gender           8068 non-null   object \n",
      " 2   Ever_Married     7928 non-null   object \n",
      " 3   Age              8068 non-null   int64  \n",
      " 4   Graduated        7990 non-null   object \n",
      " 5   Profession       7944 non-null   object \n",
      " 6   Work_Experience  7239 non-null   float64\n",
      " 7   Spending_Score   8068 non-null   object \n",
      " 8   Family_Size      7733 non-null   float64\n",
      " 9   Var_1            7992 non-null   object \n",
      " 10  Segmentation     8068 non-null   object \n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 693.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " ID                   0\n",
       " Gender               0\n",
       " Ever_Married       140\n",
       " Age                  0\n",
       " Graduated           78\n",
       " Profession         124\n",
       " Work_Experience    829\n",
       " Spending_Score       0\n",
       " Family_Size        335\n",
       " Var_1               76\n",
       " Segmentation         0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info(), df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'ID' column from the DataFrame.\n",
    "df.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8068, 9) (8068,)\n"
     ]
    }
   ],
   "source": [
    "input_cols = df.columns.drop('Segmentation')\n",
    "target_col = 'Segmentation'\n",
    "\n",
    "df_inputs = df[input_cols]\n",
    "df_target = df[target_col]\n",
    "print(df_inputs.shape, df_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Work_Experience', 'Family_Size'] ['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score', 'Var_1']\n"
     ]
    }
   ],
   "source": [
    "col_numeric = df_inputs.select_dtypes(include=[np.number]).columns.tolist()\n",
    "col_catgorical = df_inputs.select_dtypes(include='object').columns.tolist()\n",
    "print(col_numeric, col_catgorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender ['Male' 'Female']\n",
      "Ever_Married ['No' 'Yes' nan]\n",
      "Graduated ['No' 'Yes' nan]\n",
      "Profession ['Healthcare' 'Engineer' 'Lawyer' 'Entertainment' 'Artist' 'Executive'\n",
      " 'Doctor' 'Homemaker' 'Marketing' nan]\n",
      "Spending_Score ['Low' 'Average' 'High']\n",
      "Var_1 ['Cat_4' 'Cat_6' 'Cat_7' 'Cat_3' 'Cat_1' 'Cat_2' nan 'Cat_5']\n"
     ]
    }
   ],
   "source": [
    "for col in col_catgorical:\n",
    "  print(col, df_inputs[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olha Shaposhnyk\\AppData\\Local\\Temp\\ipykernel_26760\\2408797211.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_inputs.Profession.fillna('Other', inplace=True)\n",
      "C:\\Users\\Olha Shaposhnyk\\AppData\\Local\\Temp\\ipykernel_26760\\2408797211.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_inputs.Profession.fillna('Other', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Profession\n",
       "Artist           0.311849\n",
       "Healthcare       0.165097\n",
       "Entertainment    0.117625\n",
       "Engineer         0.086639\n",
       "Doctor           0.085275\n",
       "Lawyer           0.077219\n",
       "Executive        0.074244\n",
       "Marketing        0.036192\n",
       "Homemaker        0.030491\n",
       "Other            0.015369\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs.Profession.fillna('Other', inplace=True)  \n",
    "print(df_inputs.Profession.isna().sum())  \n",
    "df_inputs['Profession'].value_counts(normalize=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Family_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8068.000000</td>\n",
       "      <td>7239.000000</td>\n",
       "      <td>7733.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.466906</td>\n",
       "      <td>2.641663</td>\n",
       "      <td>2.850123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.711696</td>\n",
       "      <td>3.406763</td>\n",
       "      <td>1.531413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>89.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age  Work_Experience  Family_Size\n",
       "count  8068.000000      7239.000000  7733.000000\n",
       "mean     43.466906         2.641663     2.850123\n",
       "std      16.711696         3.406763     1.531413\n",
       "min      18.000000         0.000000     1.000000\n",
       "25%      30.000000         0.000000     2.000000\n",
       "50%      40.000000         1.000000     3.000000\n",
       "75%      53.000000         4.000000     4.000000\n",
       "max      89.000000        14.000000     9.000000"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs[col_numeric].select_dtypes(include=(np.number)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_by_mode(df, target_column, col1, col2):\n",
    "    for var_1 in df[col1].unique():\n",
    "      for var_2 in df[col2].unique():\n",
    "\n",
    "          category_mask = (df[col1] == var_1) & (df[col2] == var_2)\n",
    "          most_frequent_value = df.loc[category_mask, target_column].mode()\n",
    "\n",
    "          if not most_frequent_value.empty:\n",
    "                df.loc[category_mask & df[target_column].isnull(), target_column] = most_frequent_value.iloc[0]\n",
    "\n",
    "    df.fillna({target_column: df[target_column].mode()[0]}, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                  0\n",
      "Work_Experience    829\n",
      "Family_Size        335\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Density'>"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_inputs[col_numeric].isna().sum())\n",
    "df_inputs[['Work_Experience', 'Family_Size']].plot(kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., nan,  0.,  4.,  9., 12.,  3., 13.,  5.,  8., 14.,  7.,  2.,\n",
       "        6., 10., 11.])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs['Work_Experience'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olha Shaposhnyk\\AppData\\Local\\Temp\\ipykernel_26760\\648402858.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.fillna({target_column: df[target_column].mode()[0]}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## numerical columns\n",
    "df_inputs = impute_by_mode(df_inputs, 'Family_Size', 'Age', 'Ever_Married')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender               0\n",
      "Ever_Married       140\n",
      "Age                  0\n",
      "Graduated           78\n",
      "Profession           0\n",
      "Work_Experience      0\n",
      "Spending_Score       0\n",
      "Family_Size          0\n",
      "Var_1               76\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olha Shaposhnyk\\AppData\\Local\\Temp\\ipykernel_26760\\3256067795.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_inputs.fillna({'Work_Experience': df_inputs['Work_Experience'].median()}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "for age_group in df_inputs['Age'].unique():\n",
    "    for proff in df_inputs['Profession'].unique():\n",
    "        category_mask = (df_inputs['Age'] == age_group) & (df_inputs['Profession'] == proff)\n",
    "\n",
    "        most_frequent_value = df_inputs.loc[category_mask, 'Work_Experience'].median()\n",
    "        df_inputs.loc[category_mask & df_inputs['Work_Experience'].isnull(), 'Work_Experience'] = np.round(most_frequent_value)\n",
    "# For all values for which there are no combinations in our dataset - we fill with the usual median across the entire sample\n",
    "df_inputs.fillna({'Work_Experience': df_inputs['Work_Experience'].median()}, inplace=True)\n",
    "print(df_inputs.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olha Shaposhnyk\\AppData\\Local\\Temp\\ipykernel_26760\\1053401831.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_inputs[col_numeric] = scaler.fit_transform(df_inputs[col_numeric])\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "df_inputs[col_numeric] = scaler.fit_transform(df_inputs[col_numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olha Shaposhnyk\\AppData\\Local\\Temp\\ipykernel_26760\\648402858.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.fillna({target_column: df[target_column].mode()[0]}, inplace=True)\n",
      "C:\\Users\\Olha Shaposhnyk\\AppData\\Local\\Temp\\ipykernel_26760\\648402858.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.fillna({target_column: df[target_column].mode()[0]}, inplace=True)\n",
      "C:\\Users\\Olha Shaposhnyk\\AppData\\Local\\Temp\\ipykernel_26760\\648402858.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.fillna({target_column: df[target_column].mode()[0]}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## categorical columns\n",
    "\n",
    "df_inputs = impute_by_mode(df_inputs, 'Ever_Married', 'Age', 'Family_Size')\n",
    "df_inputs = impute_by_mode(df_inputs, 'Graduated', 'Age', 'Profession')\n",
    "df_inputs = impute_by_mode(df_inputs, 'Var_1', 'Spending_Score', 'Profession')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ever_Married    0\n",
      "Family_Size     0\n",
      "Graduated       0\n",
      "Var_1           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_inputs[['Ever_Married', 'Family_Size','Graduated','Var_1']].isna().sum())  # Print the count of missing values for specified columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Var_1']\n"
     ]
    }
   ],
   "source": [
    "cols_onehot = df_inputs.select_dtypes(include='object').columns.tolist()\n",
    "cols_onehot.remove('Spending_Score')\n",
    "print(cols_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gender_Male', 'Ever_Married_Yes', 'Graduated_Yes', 'Profession_Artist', 'Profession_Doctor', 'Profession_Engineer', 'Profession_Entertainment', 'Profession_Executive', 'Profession_Healthcare', 'Profession_Homemaker', 'Profession_Lawyer', 'Profession_Marketing', 'Profession_Other', 'Var_1_Cat_1', 'Var_1_Cat_2', 'Var_1_Cat_3', 'Var_1_Cat_4', 'Var_1_Cat_5', 'Var_1_Cat_6', 'Var_1_Cat_7']\n"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore', drop = 'if_binary')\n",
    "encoder.fit(df_inputs[cols_onehot])\n",
    "encoded_cols = list(encoder.get_feature_names_out(cols_onehot))\n",
    "print(encoded_cols)\n",
    "df_inputs[encoded_cols] = encoder.transform(df_inputs[cols_onehot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Low', 'Average', 'High'], dtype=object)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs.Spending_Score.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder(categories=[['Low', 'Average', 'High']])\n",
    "df_inputs['Spending_Score'] = ordinal_encoder.fit_transform(df_inputs[['Spending_Score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Ever_Married_Yes</th>\n",
       "      <th>Graduated_Yes</th>\n",
       "      <th>Profession_Artist</th>\n",
       "      <th>Profession_Doctor</th>\n",
       "      <th>Profession_Engineer</th>\n",
       "      <th>Profession_Entertainment</th>\n",
       "      <th>Profession_Executive</th>\n",
       "      <th>Profession_Healthcare</th>\n",
       "      <th>Profession_Homemaker</th>\n",
       "      <th>Profession_Lawyer</th>\n",
       "      <th>Profession_Marketing</th>\n",
       "      <th>Profession_Other</th>\n",
       "      <th>Var_1_Cat_1</th>\n",
       "      <th>Var_1_Cat_2</th>\n",
       "      <th>Var_1_Cat_3</th>\n",
       "      <th>Var_1_Cat_4</th>\n",
       "      <th>Var_1_Cat_5</th>\n",
       "      <th>Var_1_Cat_6</th>\n",
       "      <th>Var_1_Cat_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>-1.284623</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>-0.463482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772790</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.327151</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>-0.463482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.114061</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.408268</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>-0.463482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.203398</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.408268</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>-0.767175</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.544668</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.207467</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>0.751290</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.090249</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8063</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>-1.284623</td>\n",
       "      <td>No</td>\n",
       "      <td>Other</td>\n",
       "      <td>-0.767175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.748978</td>\n",
       "      <td>Cat_1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8064</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.506677</td>\n",
       "      <td>No</td>\n",
       "      <td>Executive</td>\n",
       "      <td>0.143904</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772790</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8065</th>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.626361</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>-0.463482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.203398</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8066</th>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>-0.985413</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>-0.463482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772790</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>-0.386993</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Executive</td>\n",
       "      <td>-0.767175</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.114061</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8068 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender Ever_Married       Age Graduated     Profession  Work_Experience  \\\n",
       "0       Male           No -1.284623        No     Healthcare        -0.463482   \n",
       "1     Female          Yes -0.327151       Yes       Engineer        -0.463482   \n",
       "2     Female          Yes  1.408268       Yes       Engineer        -0.463482   \n",
       "3       Male          Yes  1.408268       Yes         Lawyer        -0.767175   \n",
       "4     Female          Yes -0.207467       Yes  Entertainment         0.751290   \n",
       "...      ...          ...       ...       ...            ...              ...   \n",
       "8063    Male           No -1.284623        No          Other        -0.767175   \n",
       "8064    Male           No -0.506677        No      Executive         0.143904   \n",
       "8065  Female           No -0.626361       Yes     Healthcare        -0.463482   \n",
       "8066  Female           No -0.985413       Yes     Healthcare        -0.463482   \n",
       "8067    Male          Yes -0.386993       Yes      Executive        -0.767175   \n",
       "\n",
       "      Spending_Score  Family_Size  Var_1  Gender_Male  Ever_Married_Yes  \\\n",
       "0                0.0     0.772790  Cat_4          1.0               0.0   \n",
       "1                1.0     0.114061  Cat_4          0.0               1.0   \n",
       "2                0.0    -1.203398  Cat_6          0.0               1.0   \n",
       "3                2.0    -0.544668  Cat_6          1.0               1.0   \n",
       "4                2.0     2.090249  Cat_6          0.0               1.0   \n",
       "...              ...          ...    ...          ...               ...   \n",
       "8063             0.0     2.748978  Cat_1          1.0               0.0   \n",
       "8064             0.0     0.772790  Cat_4          1.0               0.0   \n",
       "8065             0.0    -1.203398  Cat_6          0.0               0.0   \n",
       "8066             0.0     0.772790  Cat_6          0.0               0.0   \n",
       "8067             1.0     0.114061  Cat_4          1.0               1.0   \n",
       "\n",
       "      Graduated_Yes  Profession_Artist  Profession_Doctor  \\\n",
       "0               0.0                0.0                0.0   \n",
       "1               1.0                0.0                0.0   \n",
       "2               1.0                0.0                0.0   \n",
       "3               1.0                0.0                0.0   \n",
       "4               1.0                0.0                0.0   \n",
       "...             ...                ...                ...   \n",
       "8063            0.0                0.0                0.0   \n",
       "8064            0.0                0.0                0.0   \n",
       "8065            1.0                0.0                0.0   \n",
       "8066            1.0                0.0                0.0   \n",
       "8067            1.0                0.0                0.0   \n",
       "\n",
       "      Profession_Engineer  Profession_Entertainment  Profession_Executive  \\\n",
       "0                     0.0                       0.0                   0.0   \n",
       "1                     1.0                       0.0                   0.0   \n",
       "2                     1.0                       0.0                   0.0   \n",
       "3                     0.0                       0.0                   0.0   \n",
       "4                     0.0                       1.0                   0.0   \n",
       "...                   ...                       ...                   ...   \n",
       "8063                  0.0                       0.0                   0.0   \n",
       "8064                  0.0                       0.0                   1.0   \n",
       "8065                  0.0                       0.0                   0.0   \n",
       "8066                  0.0                       0.0                   0.0   \n",
       "8067                  0.0                       0.0                   1.0   \n",
       "\n",
       "      Profession_Healthcare  Profession_Homemaker  Profession_Lawyer  \\\n",
       "0                       1.0                   0.0                0.0   \n",
       "1                       0.0                   0.0                0.0   \n",
       "2                       0.0                   0.0                0.0   \n",
       "3                       0.0                   0.0                1.0   \n",
       "4                       0.0                   0.0                0.0   \n",
       "...                     ...                   ...                ...   \n",
       "8063                    0.0                   0.0                0.0   \n",
       "8064                    0.0                   0.0                0.0   \n",
       "8065                    1.0                   0.0                0.0   \n",
       "8066                    1.0                   0.0                0.0   \n",
       "8067                    0.0                   0.0                0.0   \n",
       "\n",
       "      Profession_Marketing  Profession_Other  Var_1_Cat_1  Var_1_Cat_2  \\\n",
       "0                      0.0               0.0          0.0          0.0   \n",
       "1                      0.0               0.0          0.0          0.0   \n",
       "2                      0.0               0.0          0.0          0.0   \n",
       "3                      0.0               0.0          0.0          0.0   \n",
       "4                      0.0               0.0          0.0          0.0   \n",
       "...                    ...               ...          ...          ...   \n",
       "8063                   0.0               1.0          1.0          0.0   \n",
       "8064                   0.0               0.0          0.0          0.0   \n",
       "8065                   0.0               0.0          0.0          0.0   \n",
       "8066                   0.0               0.0          0.0          0.0   \n",
       "8067                   0.0               0.0          0.0          0.0   \n",
       "\n",
       "      Var_1_Cat_3  Var_1_Cat_4  Var_1_Cat_5  Var_1_Cat_6  Var_1_Cat_7  \n",
       "0             0.0          1.0          0.0          0.0          0.0  \n",
       "1             0.0          1.0          0.0          0.0          0.0  \n",
       "2             0.0          0.0          0.0          1.0          0.0  \n",
       "3             0.0          0.0          0.0          1.0          0.0  \n",
       "4             0.0          0.0          0.0          1.0          0.0  \n",
       "...           ...          ...          ...          ...          ...  \n",
       "8063          0.0          0.0          0.0          0.0          0.0  \n",
       "8064          0.0          1.0          0.0          0.0          0.0  \n",
       "8065          0.0          0.0          0.0          1.0          0.0  \n",
       "8066          0.0          0.0          0.0          1.0          0.0  \n",
       "8067          0.0          1.0          0.0          0.0          0.0  \n",
       "\n",
       "[8068 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "display(df_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'Work_Experience',\n",
       " 'Family_Size',\n",
       " 'Spending_Score',\n",
       " 'Gender_Male',\n",
       " 'Ever_Married_Yes',\n",
       " 'Graduated_Yes',\n",
       " 'Profession_Artist',\n",
       " 'Profession_Doctor',\n",
       " 'Profession_Engineer',\n",
       " 'Profession_Entertainment',\n",
       " 'Profession_Executive',\n",
       " 'Profession_Healthcare',\n",
       " 'Profession_Homemaker',\n",
       " 'Profession_Lawyer',\n",
       " 'Profession_Marketing',\n",
       " 'Profession_Other',\n",
       " 'Var_1_Cat_1',\n",
       " 'Var_1_Cat_2',\n",
       " 'Var_1_Cat_3',\n",
       " 'Var_1_Cat_4',\n",
       " 'Var_1_Cat_5',\n",
       " 'Var_1_Cat_6',\n",
       " 'Var_1_Cat_7']"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_train = col_numeric + ['Spending_Score'] + encoded_cols \n",
    "cols_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Ever_Married_Yes</th>\n",
       "      <th>Graduated_Yes</th>\n",
       "      <th>Profession_Artist</th>\n",
       "      <th>Profession_Doctor</th>\n",
       "      <th>Profession_Engineer</th>\n",
       "      <th>Profession_Entertainment</th>\n",
       "      <th>Profession_Executive</th>\n",
       "      <th>Profession_Healthcare</th>\n",
       "      <th>Profession_Homemaker</th>\n",
       "      <th>Profession_Lawyer</th>\n",
       "      <th>Profession_Marketing</th>\n",
       "      <th>Profession_Other</th>\n",
       "      <th>Var_1_Cat_1</th>\n",
       "      <th>Var_1_Cat_2</th>\n",
       "      <th>Var_1_Cat_3</th>\n",
       "      <th>Var_1_Cat_4</th>\n",
       "      <th>Var_1_Cat_5</th>\n",
       "      <th>Var_1_Cat_6</th>\n",
       "      <th>Var_1_Cat_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.284623</td>\n",
       "      <td>-0.463482</td>\n",
       "      <td>0.772790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.327151</td>\n",
       "      <td>-0.463482</td>\n",
       "      <td>0.114061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.408268</td>\n",
       "      <td>-0.463482</td>\n",
       "      <td>-1.203398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.408268</td>\n",
       "      <td>-0.767175</td>\n",
       "      <td>-0.544668</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.207467</td>\n",
       "      <td>0.751290</td>\n",
       "      <td>2.090249</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8063</th>\n",
       "      <td>-1.284623</td>\n",
       "      <td>-0.767175</td>\n",
       "      <td>2.748978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8064</th>\n",
       "      <td>-0.506677</td>\n",
       "      <td>0.143904</td>\n",
       "      <td>0.772790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8065</th>\n",
       "      <td>-0.626361</td>\n",
       "      <td>-0.463482</td>\n",
       "      <td>-1.203398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8066</th>\n",
       "      <td>-0.985413</td>\n",
       "      <td>-0.463482</td>\n",
       "      <td>0.772790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>-0.386993</td>\n",
       "      <td>-0.767175</td>\n",
       "      <td>0.114061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8068 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age  Work_Experience  Family_Size  Spending_Score  Gender_Male  \\\n",
       "0    -1.284623        -0.463482     0.772790             0.0          1.0   \n",
       "1    -0.327151        -0.463482     0.114061             1.0          0.0   \n",
       "2     1.408268        -0.463482    -1.203398             0.0          0.0   \n",
       "3     1.408268        -0.767175    -0.544668             2.0          1.0   \n",
       "4    -0.207467         0.751290     2.090249             2.0          0.0   \n",
       "...        ...              ...          ...             ...          ...   \n",
       "8063 -1.284623        -0.767175     2.748978             0.0          1.0   \n",
       "8064 -0.506677         0.143904     0.772790             0.0          1.0   \n",
       "8065 -0.626361        -0.463482    -1.203398             0.0          0.0   \n",
       "8066 -0.985413        -0.463482     0.772790             0.0          0.0   \n",
       "8067 -0.386993        -0.767175     0.114061             1.0          1.0   \n",
       "\n",
       "      Ever_Married_Yes  Graduated_Yes  Profession_Artist  Profession_Doctor  \\\n",
       "0                  0.0            0.0                0.0                0.0   \n",
       "1                  1.0            1.0                0.0                0.0   \n",
       "2                  1.0            1.0                0.0                0.0   \n",
       "3                  1.0            1.0                0.0                0.0   \n",
       "4                  1.0            1.0                0.0                0.0   \n",
       "...                ...            ...                ...                ...   \n",
       "8063               0.0            0.0                0.0                0.0   \n",
       "8064               0.0            0.0                0.0                0.0   \n",
       "8065               0.0            1.0                0.0                0.0   \n",
       "8066               0.0            1.0                0.0                0.0   \n",
       "8067               1.0            1.0                0.0                0.0   \n",
       "\n",
       "      Profession_Engineer  Profession_Entertainment  Profession_Executive  \\\n",
       "0                     0.0                       0.0                   0.0   \n",
       "1                     1.0                       0.0                   0.0   \n",
       "2                     1.0                       0.0                   0.0   \n",
       "3                     0.0                       0.0                   0.0   \n",
       "4                     0.0                       1.0                   0.0   \n",
       "...                   ...                       ...                   ...   \n",
       "8063                  0.0                       0.0                   0.0   \n",
       "8064                  0.0                       0.0                   1.0   \n",
       "8065                  0.0                       0.0                   0.0   \n",
       "8066                  0.0                       0.0                   0.0   \n",
       "8067                  0.0                       0.0                   1.0   \n",
       "\n",
       "      Profession_Healthcare  Profession_Homemaker  Profession_Lawyer  \\\n",
       "0                       1.0                   0.0                0.0   \n",
       "1                       0.0                   0.0                0.0   \n",
       "2                       0.0                   0.0                0.0   \n",
       "3                       0.0                   0.0                1.0   \n",
       "4                       0.0                   0.0                0.0   \n",
       "...                     ...                   ...                ...   \n",
       "8063                    0.0                   0.0                0.0   \n",
       "8064                    0.0                   0.0                0.0   \n",
       "8065                    1.0                   0.0                0.0   \n",
       "8066                    1.0                   0.0                0.0   \n",
       "8067                    0.0                   0.0                0.0   \n",
       "\n",
       "      Profession_Marketing  Profession_Other  Var_1_Cat_1  Var_1_Cat_2  \\\n",
       "0                      0.0               0.0          0.0          0.0   \n",
       "1                      0.0               0.0          0.0          0.0   \n",
       "2                      0.0               0.0          0.0          0.0   \n",
       "3                      0.0               0.0          0.0          0.0   \n",
       "4                      0.0               0.0          0.0          0.0   \n",
       "...                    ...               ...          ...          ...   \n",
       "8063                   0.0               1.0          1.0          0.0   \n",
       "8064                   0.0               0.0          0.0          0.0   \n",
       "8065                   0.0               0.0          0.0          0.0   \n",
       "8066                   0.0               0.0          0.0          0.0   \n",
       "8067                   0.0               0.0          0.0          0.0   \n",
       "\n",
       "      Var_1_Cat_3  Var_1_Cat_4  Var_1_Cat_5  Var_1_Cat_6  Var_1_Cat_7  \n",
       "0             0.0          1.0          0.0          0.0          0.0  \n",
       "1             0.0          1.0          0.0          0.0          0.0  \n",
       "2             0.0          0.0          0.0          1.0          0.0  \n",
       "3             0.0          0.0          0.0          1.0          0.0  \n",
       "4             0.0          0.0          0.0          1.0          0.0  \n",
       "...           ...          ...          ...          ...          ...  \n",
       "8063          0.0          0.0          0.0          0.0          0.0  \n",
       "8064          0.0          1.0          0.0          0.0          0.0  \n",
       "8065          0.0          0.0          0.0          1.0          0.0  \n",
       "8066          0.0          0.0          0.0          1.0          0.0  \n",
       "8067          0.0          1.0          0.0          0.0          0.0  \n",
       "\n",
       "[8068 rows x 24 columns]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs = df_inputs[cols_train]\n",
    "train_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6454, 24), (1614, 24), (6454,), (1614,))"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_inputs, df_target, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions 1\n",
    "\n",
    "- Dataset dimensions: 11 columns (of which 1 is the class label and another column is ID which we remove, so we have 9 features) and 8068 rows of records.\n",
    "- Let's look at which columns have missing data.\n",
    "\n",
    "|column           |Missing value |\n",
    "|-----------------|--------|\n",
    "|Ever_Married      |140|\n",
    "|Graduated         | 78|\n",
    "|Profession        |124|\n",
    "|Work_Experience   |829|\n",
    "|Family_Size       |335|\n",
    "|Var_1             | 76|\n",
    "\n",
    "- For handling missing values, we created a function *impute_by_mode* where we will use the mode to fill in the gaps, especially for categorical data. We pass two columns that can significantly influence the column with missing values, and based on the mode in these defined groups, we fill in the gaps. We find the mode for cases that are similar to each other and fill in the missing values. If such groups do not exist, we use the global mode.\n",
    "\n",
    "- We identify numerical *['Age', 'Work_Experience', 'Family_Size']* and process the missing values.\n",
    "    - Work_Experience - according to descriptive statistics, at least 25% of the records have 0 years of experience. We group the column by Profession and Age (these columns seem to be those that can greatly influence your experience) and fill in the missing values with the median. The distribution of this column is multimodal (with peaks at 0 and 7), so we choose the median relative to the groups.\n",
    "    - Family_Size - we fill in the mode based on the family size and how many years it has existed (grouping by 'Age', 'Ever_Married').\n",
    "- We standardize the numerical columns using *StandardScaler*.\n",
    "\n",
    "- We identify categorical *['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score', 'Var_1']* and process the missing values.\n",
    "    - Ever_Married - similarly, we fill in the mode based on groups by 'Age', 'Family_Size'. Alternatively, it could have been left as *'Other'*.\n",
    "    - Graduated - similarly, we fill in the mode based on groups by 'Age', 'Profession'. Alternatively, it could have been left as *'Other'*.\n",
    "    - Profession - has 9 unique values, among which **Artist=31%** stands out significantly. All missing values are filled with *'Other'*, which will account for 1.5% of all data.\n",
    "    - Var_1 - the category has 7 columns. Ideally, we would group the data by all other columns, but we will choose only two for grouping 'Spending_Score', 'Profession' to fill in the mode.\n",
    "- We encode our categorical columns using *OneHotEncoder* (excluding Spending_Score).\n",
    "- We encode Spending_Score using *OrdinalEncoder* because it contains ordinal values low-medium-high ['Low', 'Average', 'High'] = 0,1,2.\n",
    "\n",
    "- We form our final dataset which includes: col_numeric + ['Spending_Score'] + encoded_cols.\n",
    "- Segmentation - target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhJzCBA7P0f8"
   },
   "source": [
    "**Task 2. It is important to read the entire wording of this task carefully to the end!**\n",
    "\n",
    "Apply the SMOTE and SMOTE-Tomek resampling methods from the imbalanced-learn library to the training sample. As a result, you should have 2 training sets: one with upsampling using SMOTE and the other with resampling using SMOTE-Tomek.\n",
    "\n",
    "Attention! In our dataset, there are both categorical and regular numerical data. Basic SMOTE will not work correctly with categorical data, but there is a modification that will. Therefore, this task has 2 parts:\n",
    "\n",
    "1. Apply basic SMOTE only to NON-categorical features.\n",
    "\n",
    "2. Review the information about the [SMOTENC](https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.SMOTENC.html#imblearn.over_sampling.SMOTENC) method and use this method in this task. You will receive +3 points for this task, and it is recommended for execution.\n",
    "\n",
    "  **Hint**: To use SMOTENC, you need to create a variable that contains the indices of the features that are categorical (their number among the columns) and pass it when initializing an instance of the `SMOTENC(..., categorical_features=cat_feature_indices)` class.\n",
    "  \n",
    "  You can also consider using the variation of SMOTE that works ONLY with categorical features [SMOTEN](https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.SMOTEN.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6NFUkQ_15HNX"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, SMOTENC, SMOTEN\n",
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat.Indices: [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n"
     ]
    }
   ],
   "source": [
    "categorical_indices = [train_inputs.columns.get_loc(col) for col in (['Spending_Score'] + encoded_cols)]\n",
    "print(\"Cat.Indices:\", categorical_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8068, 24),\n",
       " Segmentation\n",
       " D    0.277967\n",
       " C    0.246359\n",
       " A    0.244964\n",
       " B    0.230710\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape, y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7176, 24),\n",
       " Segmentation\n",
       " A    0.25\n",
       " D    0.25\n",
       " B    0.25\n",
       " C    0.25\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_cat = SMOTENC(categorical_features=categorical_indices, random_state=42)\n",
    "X_train_smoteCAT, y_train_smoteCAT = smote_cat.fit_resample(X_train, y_train)\n",
    "X_train_smoteCAT.shape, y_train_smoteCAT.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5802, 24),\n",
       " Segmentation\n",
       " D    0.256291\n",
       " C    0.255946\n",
       " B    0.245088\n",
       " A    0.242675\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoteTom = SMOTETomek(random_state=42)  \n",
    "X_train_smoteTOM, y_train_smoteTOM = smoteTom.fit_resample(X_train, y_train)  \n",
    "X_train_smoteTOM.shape, y_train_smoteTOM.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7176, 3),\n",
       " Segmentation\n",
       " A    0.25\n",
       " D    0.25\n",
       " B    0.25\n",
       " C    0.25\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_num = SMOTE(random_state=42)\n",
    "X_train_smoteNUM, y_train_smoteNUM = smote_num.fit_resample(X_train[col_numeric], y_train)\n",
    "X_train_smoteNUM.shape, y_train_smoteNUM.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions 2\n",
    "\n",
    "- We consider the columns ['Spending_Score'] + encoded_cols as categorical and find their indices = from 3 to 23\n",
    "- The original distribution among classes is approximately equal, only category D stands out slightly in quantity\n",
    "  - D   = 0.28\n",
    "  - C   = 0.25\n",
    "  - A   = 0.24\n",
    "  - B   = 0.23\n",
    "\n",
    "- To use numerical and categorical data, we use SMOTENC, where we pass the indices of our columns SMOTENC(categorical_features=categorical_indices, random_state=42). Thus, all classes are now evenly distributed at 25%\n",
    "- Next, we similarly use SMOTETomek, because after SMOTE the algorithm additionally removes connections, the distribution of classes has changed slightly\n",
    "  - D    0.256\n",
    "  - C    0.256\n",
    "  - B    0.245\n",
    "  - A    0.243\n",
    "\n",
    "- Also, for an additional experiment, we will use SMOTE only on numerical columns, meaning that further training of the classifier will occur only on 3 columns for this case (X_train[col_numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ja4w_GgmT4D0"
   },
   "source": [
    "**Task 3**.\n",
    "  1. Train a logistic regression model using the One-vs-Rest strategy with logistic regression on the original data, balanced with SMOTE, and balanced with Smote-Tomek.  \n",
    "  2. Measure the quality of each trained model using `sklearn.metrics.classification_report`.\n",
    "  3. Write down which metric you chose for comparing the models.\n",
    "  4. Which model is the best?\n",
    "  5. If there is no significant difference between the models - write your hypothesis as to why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "id": "nxWVeRan5JBh"
   },
   "outputs": [],
   "source": [
    "def model_train_sample(X, y, validation):\n",
    "    log = LogisticRegression(random_state=42)\n",
    "    ovr = OneVsRestClassifier(log)\n",
    "    ovr.fit(X, y)\n",
    "    predict = ovr.predict(validation)\n",
    "    return predict\n",
    "\n",
    "# Original probabilities\n",
    "prob_original = model_train_sample(X_train, y_train, X_val)\n",
    "# Probabilities with SMOTE for categorical features\n",
    "prob_smoteCAT = model_train_sample(X_train_smoteCAT, y_train_smoteCAT, X_val)\n",
    "# Probabilities with SMOTE for TOM\n",
    "prob_smoteTOM = model_train_sample(X_train_smoteTOM, y_train_smoteTOM, X_val)\n",
    "# Probabilities with SMOTE for numerical features\n",
    "prob_smoteNUM = model_train_sample(X_train_smoteNUM, y_train_smoteNUM, X_val[col_numeric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.41      0.47      0.44       391\n",
      "           B       0.43      0.12      0.18       369\n",
      "           C       0.46      0.65      0.54       380\n",
      "           D       0.65      0.71      0.68       474\n",
      "\n",
      "    accuracy                           0.50      1614\n",
      "   macro avg       0.49      0.49      0.46      1614\n",
      "weighted avg       0.50      0.50      0.47      1614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'ORIGINAL REPORT\\n{classification_report(y_val, prob_original)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTENC REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.41      0.50      0.45       391\n",
      "           B       0.39      0.15      0.22       369\n",
      "           C       0.46      0.63      0.53       380\n",
      "           D       0.68      0.68      0.68       474\n",
      "\n",
      "    accuracy                           0.50      1614\n",
      "   macro avg       0.48      0.49      0.47      1614\n",
      "weighted avg       0.50      0.50      0.48      1614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'SMOTENC REPORT\\n{classification_report(y_val, prob_smoteCAT)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE-TOMEK REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.42      0.51      0.46       391\n",
      "           B       0.41      0.17      0.24       369\n",
      "           C       0.46      0.63      0.53       380\n",
      "           D       0.68      0.68      0.68       474\n",
      "\n",
      "    accuracy                           0.51      1614\n",
      "   macro avg       0.49      0.50      0.48      1614\n",
      "weighted avg       0.50      0.51      0.49      1614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'SMOTE-TOMEK REPORT\\n{classification_report(y_val, prob_smoteTOM)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE NUMERICAL REPORT\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.32      0.34      0.33       391\n",
      "           B       0.24      0.11      0.15       369\n",
      "           C       0.37      0.38      0.38       380\n",
      "           D       0.52      0.71      0.60       474\n",
      "\n",
      "    accuracy                           0.41      1614\n",
      "   macro avg       0.36      0.39      0.37      1614\n",
      "weighted avg       0.37      0.41      0.38      1614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'SMOTE NUMERICAL REPORT\\n{classification_report(y_val, prob_smoteNUM)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions 3\n",
    "\n",
    "- We will train 4 classifiers: using the original data without balancing, SMOTENC, SMOTE-TOMEK, and SMOTE only with numerical columns\n",
    "\n",
    "|Method                 |  Macro Avg F1-Score|\n",
    "|-----------------------|-----|\n",
    "|Original               |  0.46 | \n",
    "|SMOTENC cat+num        | 0.47 | \n",
    "|SMOTE-TOMEK            | 0.48 | \n",
    "|SMOTE Numerical only   |  0.37 | \n",
    "\n",
    "\n",
    "- As the main metric, we will use *Macro Avg F1-Score*, as it is more informative than accuracy and provides a general representation of model precision, balancing between precision and recall.\n",
    "- Thus, SMOTE-TOMEK performed the best, handling classification for class *B = F1 = 0.24* better; this is the most \"problematic\" class, as all classifiers showed low performance for it. Meanwhile, SMOTENC is only 0.01 behind it. It can be said that both of these models performed well, although SMOTE-TOMEK has a slight advantage.\n",
    "\n",
    "- The model on the original data has a slightly lower accuracy of 0.46, but a much lower score for the local class B = 0.18. While all other classes have a local f1-score of at least above 0.44.\n",
    "- SMOTE only with numerical features showed the worst accuracy, which may indicate that categorical features in this dataset are of great importance. Therefore, it is advisable to use the entire dataset for analysis.\n",
    "\n",
    "`If there is no significant difference between the models - write your hypothesis, why?`\n",
    "- In my opinion, SMOTENC and SMOTE-TOMEK showed almost the same result because there were almost no Tomek links in the data, or they were arranged in such a way that after removing some points, the overall class distribution remained approximately the same, and this did not affect the construction of boundaries between classes.\n",
    "- Similarly, compared to the original dataset, it can be assumed that since the data were already distributed almost equally, their balancing did not lead to significant changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ml_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
